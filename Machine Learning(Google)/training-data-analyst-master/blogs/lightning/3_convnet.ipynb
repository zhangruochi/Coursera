{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network on pixel neighborhoods\n",
    "\n",
    "This notebook reads the pixel-neighborhood data written out by the Dataflow program of [1_explore.ipynb](./1_explore.ipynb) and trains a simple convnet model on Cloud ML Engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'cloud-training-demos-ml'\n",
    "PROJECT = 'cloud-training-demos'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'Y' | gcloud components update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade tensorflow cloudml-hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PWD}/ltgpred/\n",
    "OUTDIR=${PWD}/cnn_trained\n",
    "DATADIR=${PWD}/preproc/tfrecord\n",
    "rm -rf $OUTDIR\n",
    "python -m trainer.train_cnn \\\n",
    "    --train_steps=10 --num_eval_records=512 --train_batch_size=16 --num_cores=1 --nlayers=5 --arch=convnet \\\n",
    "    --job-dir=$OUTDIR --train_data_path=${DATADIR}/train* --eval_data_path=${DATADIR}/eval*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "saved_model_cli show --all --dir $(ls -d -1 /content/blogs/lightning/cnn_trained/export/exporter/* | tail -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export CLOUDSDK_PYTHON=$(which python3)\n",
    "OUTDIR=${PWD}/cnn_trained\n",
    "DATADIR=${PWD}/preproc/tfrecord\n",
    "rm -rf $OUTDIR\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.train_cnn --package-path=${PWD}/ltgpred/trainer \\\n",
    "    -- \\\n",
    "    --train_steps=10 --num_eval_records=512 --train_batch_size=16 --num_cores=1 --nlayers=5 \\\n",
    "    --job-dir=$OUTDIR --train_data_path=${DATADIR}/train* --eval_data_path=${DATADIR}/eval*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training lighting prediction model on CMLE using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_model_m_gpu is a machine with 4 K-80 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile largemachine.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: complex_model_m_p100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#DATADIR=gs://$BUCKET/lightning/preproc/tfrecord\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "\n",
    "#for ARCH in feateng convnet dnn resnet; do\n",
    "for ARCH in convnet; do\n",
    "  JOBNAME=ltgpred_${ARCH}_$(date -u +%y%m%d_%H%M%S)\n",
    "  OUTDIR=gs://${BUCKET}/lightning/${ARCH}_trained_gpu\n",
    "  gsutil -m rm -rf $OUTDIR\n",
    "  gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "      --module-name trainer.train_cnn --package-path ${PWD}/ltgpred/trainer --job-dir=$OUTDIR \\\n",
    "      --region=${REGION} --scale-tier CUSTOM --config largemachine.yaml \\\n",
    "      --python-version 3.5 --runtime-version 1.10 \\\n",
    "      -- \\\n",
    "      --train_data_path ${DATADIR}/train-* --eval_data_path ${DATADIR}/eval-* \\\n",
    "      --train_steps 5000 --train_batch_size 256 --num_cores 4 --arch $ARCH \\\n",
    "      --num_eval_records 1024000 --nlayers 5 --dprob 0 --ksize 3 --nfil 10 --learning_rate 0.01 \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Results (Dropout=0)\n",
    "| Architecture | Training time | Validation RMSE | Validation Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| feateng | 23 min | 0.2620 | 0.8233 |\n",
    "| dnn | 62 min | 0.2752 | 0.8272 |\n",
    "| convnet | 24 min | 0.2261 | 0.8462 |\n",
    "| resnet | 63 min | 0.3088 | 0.7142 |\n",
    "\n",
    "### Results (Dropout=0.05)\n",
    "| Architecture | Training time | Validation RMSE | Validation Accuracy |\n",
    "| --- | --- | --- | --- |\n",
    "| feateng | 20 min | 0.2641 | 0.8258 |\n",
    "| dnn | 58 min | 0.2284 | 0.8412 |\n",
    "| convnet | 23 min | 0.2268 | 0.8459 |\n",
    "| resnet | 80 min | 0.3005 | 0.6887 |\n",
    "\n",
    "\n",
    "Other than for the dnn, dropout doesn't seem to help.  Based on these results, let's train a <b> convnet with no dropout </b>.\n",
    "\n",
    "All the results above are for \n",
    "<pre>\n",
    "--train_steps=5000 --train_batch_size=256 --num_cores=4 --arch=$ARCH \\\n",
    "--num_eval_records=1024000 --nlayers=5 --dprob=... --ksize=3 --nfil=10 --learning_rate=0.01\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hyperparam_gpu.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam_gpu.yaml\n",
    "trainingInput:\n",
    "  scaleTier: CUSTOM\n",
    "  masterType: complex_model_m_p100\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 2\n",
    "    hyperparameterMetricTag: val_acc\n",
    "    params:\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: nfil\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 30\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: nlayers\n",
    "      type: INTEGER\n",
    "      minValue: 1\n",
    "      maxValue: 5\n",
    "      scaleType: UNIT_LINEAR_SCALE     \n",
    "    - parameterName: train_batch_size # has to be multiple of 128\n",
    "      type: DISCRETE\n",
    "      discreteValues: [128, 256, 512, 1024, 2048, 4096]       \n",
    "\n",
    "#    - parameterName: arch\n",
    "#      type: CATEGORICAL\n",
    "#      categoricalValues: [\"convnet\", \"feateng\", \"resnet\", \"dnn\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/lightning/convnet_trained_gpu_hparam\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "JOBNAME=ltgpred_hparam_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --module-name=ltgpred.trainer.train_cnn --package-path=${PWD}/ltgpred --job-dir=$OUTDIR \\\n",
    "    --region=${REGION} --scale-tier=CUSTOM --config=hyperparam_gpu.yaml \\\n",
    "    --python-version=3.5 --runtime-version=1.10 \\\n",
    "    -- \\\n",
    "    --train_data_path=${DATADIR}/train-* --eval_data_path=${DATADIR}/eval-* \\\n",
    "    --train_steps=5000 --train_batch_size=256 --num_cores=4 --arch=convnet \\\n",
    "    --num_eval_records=1024000 --nlayers=5 --dprob=0 --ksize=3 --nfil=10 --learning_rate=0.01 --skipexport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter training took 7.5 hours for me, cost 215 ML units (about 110USD list price) and had this as the best set of parameters:\n",
    "<pre>\n",
    "{\n",
    "      \"trialId\": \"2\",\n",
    "      \"hyperparameters\": {\n",
    "        \"nfil\": \"10\",\n",
    "        \"learning_rate\": \"0.02735530997243607\",\n",
    "        \"train_batch_size\": \"1024\",\n",
    "        \"nlayers\": \"3\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1\",\n",
    "        \"objectiveValue\": 0.846787109375\n",
    "      }\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training lightning prediction model on CMLE using TPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train on the TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: ltgpred_cnn_181222_005138\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-training-demos-ml/lightning/cnn_trained_tpu/packages/b03f282748599540f05d2a39193b4a60d99b940b0b436acea2427ccbe7d1913e/ltgpred-0.0.1.tar.gz#1545437567846144...\n",
      "/ [1/1 objects] 100% Done                                                       \r\n",
      "Operation completed over 1 objects.                                              \n",
      "Job [ltgpred_cnn_181222_005138] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe ltgpred_cnn_181222_005138\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs ltgpred_cnn_181222_005138\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/lightning/cnn_trained_tpu\n",
    "DATADIR=gs://$BUCKET/lightning/preproc_0.02_32_2/tfrecord\n",
    "JOBNAME=ltgpred_cnn_$(date -u +%y%m%d_%H%M%S)\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "    --module-name ltgpred.trainer.train_cnn --package-path ${PWD}/ltgpred --job-dir=$OUTDIR \\\n",
    "    --region ${REGION} --scale-tier BASIC_TPU \\\n",
    "    --python-version 3.5 --runtime-version 1.12 \\\n",
    "    -- \\\n",
    "    --train_data_path ${DATADIR}/train* --eval_data_path ${DATADIR}/eval* \\\n",
    "    --train_steps 10000 --train_batch_size 1024 --num_cores 8  --use_tpu \\\n",
    "    --num_eval_records 128000 --nlayers 5 --dprob 0.05 --ksize 3 --nfil 10 --learning_rate 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, training finished with accuracy=\n",
    "\n",
    "(Wait for 1.12 or higher since the new Keras export capability is not present in 1.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
